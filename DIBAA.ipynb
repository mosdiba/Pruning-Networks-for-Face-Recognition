{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fa19232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "from matplotlib.image import imread\n",
    "from glob import glob\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a5659e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32fc3afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf436c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55ee9e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f92abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'casia-amin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2447b2cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import EfficientNetB0\n",
    "# eff = EfficientNetB0(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "from tensorflow.keras.applications import ResNet50V2\n",
    "model = ResNet50V2(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)\n",
    "\n",
    "# model = tf.keras.applications.ResNet50V2(\n",
    "#         include_top=False,\n",
    "#         weights=None,\n",
    "#         input_tensor=None,\n",
    "#         input_shape=IMAGE_SIZE + [3],\n",
    "#         pooling=None,\n",
    "#         classes=1000,\n",
    "#         classifier_activation=\"softmax\")\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8256d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import EfficientNetB1\n",
    "# eff1 = EfficientNetB1(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312ab304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import EfficientNetB2\n",
    "# eff2 = EfficientNetB2(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd21b01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import EfficientNetB3\n",
    "# eff3 = EfficientNetB3(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4513dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import EfficientNetB4\n",
    "# eff34 = EfficientNetB4(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e321ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import EfficientNetB5\n",
    "# eff5 = EfficientNetB5(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d3c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.applications import VGG19\n",
    "# vgg19 = VGG19(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13aaab81",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(model.layers[-7].output.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37339a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae651023",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob('casia-amin/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7d2d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "headModel = model.output\n",
    "headModel = Flatten()(headModel)\n",
    "headModel=Dense(256, activation='relu', name='fc1',kernel_initializer=glorot_uniform(seed=0))(headModel)\n",
    "headModel=Dense(128, activation='relu', name='fc2',kernel_initializer=glorot_uniform(seed=0))(headModel)\n",
    "headModel = Dense( len(folders) ,activation='softmax', name='fc3',kernel_initializer=glorot_uniform(seed=0))(headModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a5f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "# x = Flatten()(model.output)\n",
    "# # x = Dense(1000, activation='relu')(x)\n",
    "# prediction = Dense(len(folders), activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "515eee40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = Model(inputs=model.input, outputs=prediction)\n",
    "\n",
    "model = Model(inputs=model.input, outputs=headModel)\n",
    "\n",
    "# view the structure of the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71654674",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.000001)\n",
    "    \n",
    "model.compile(\n",
    "  loss='categorical_crossentropy' ,\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9152d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   validation_split=0.2)\n",
    "\n",
    "# test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 16,\n",
    "                                                 class_mode = 'categorical',\n",
    "                                                 subset = 'training')\n",
    "\n",
    "test_set = train_datagen.flow_from_directory(train_path,\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 16,\n",
    "                                            class_mode = 'categorical',\n",
    "                                            subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed37298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "es=EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "711f0826",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc = ModelCheckpoint('/best_model.h5', monitor='val_accuracy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ff07d79",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "r = model.fit(\n",
    "    training_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=70,\n",
    "    callbacks=[mc,es]\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5e86a941",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model.save('model_Resnet50v2_70epoch_.58valaccuracy .h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1e9f1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(input_image, filter_index):\n",
    "    activation = feature_extractor(input_image)\n",
    "    # We avoid border artifacts by only involving non-border pixels in the loss.\n",
    "    filter_activation = activation[:, 2:-2, 2:-2, filter_index]\n",
    "    return tf.reduce_mean(filter_activation)\n",
    "\n",
    "\n",
    "def gradient_ascent_step(img, filter_index):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(img)\n",
    "        loss = compute_loss(img, filter_index)\n",
    "    # Compute gradients.\n",
    "    grads = tape.gradient(loss, img)\n",
    "    return loss, grads\n",
    "\n",
    "#simple image scaling to (nR x nC) size\n",
    "def scale(im, nR, nC):\n",
    "  nR0 = len(im)     # source number of rows \n",
    "  nC0 = len(im[0])  # source number of columns \n",
    "  return [[ im[int(nR0 * r / nR)][int(nC0 * c / nC)]  \n",
    "             for c in range(nC)] for r in range(nR)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c819a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "\n",
    "# def load_images_from_folder(folder):\n",
    "#     images = []\n",
    "#     for filename in glob(folder):\n",
    "#         img = cv2.imread(os.path.join(folder,filename))\n",
    "#         if img is not None:\n",
    "#             images.append(img)\n",
    "#     return images\n",
    "images=[]\n",
    "images_dir = glob.glob(\"selected/*\")\n",
    "for dir_ in images_dir:\n",
    "    images.append(cv2.imread(dir_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f97207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fee944c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.vis import utils\n",
    "# !pip show keras_vis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f10a84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip show keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c4f70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d50e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf_keras_vis import utils\n",
    "# # from tf.keras.vis.utils import utils\n",
    "# import vis\n",
    "# import vis.utils as utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62188e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_enumerate(iterable):\n",
    "    \n",
    "    return zip(reversed(range(len(iterable))), reversed(iterable))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6dfa9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_layer_idx(model, layer_name):\n",
    " \n",
    "    layer_idx = None\n",
    "    for idx, layer in enumerate(model.layers):\n",
    "        if layer.name == layer_name:\n",
    "            layer_idx = idx\n",
    "            break\n",
    "    if layer_idx is None:\n",
    "        raise ValueError(\"No layer with name '{}' within the model\".format(layer_name))\n",
    "    return layer_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3e121a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dead_filters = {}\n",
    "\n",
    "for img in images:\n",
    "    img_tf = tf.convert_to_tensor(scale(img, 224, 224), np.float32)\n",
    "    img_tf = tf.reshape(img_tf, [-1, 224, 224, 3])\n",
    "\n",
    "    for layer in model.layers:\n",
    "\n",
    "        layer_name = layer.name\n",
    "        \n",
    "        feature_extractor = keras.Model(inputs = model.inputs, outputs = layer.output)\n",
    "\n",
    "        if layer_name[-layer_name[::-1].find('_'):] == 'relu':\n",
    "\n",
    "            layer_idx =find_layer_idx(model, layer_name) -1\n",
    "            \n",
    "            dead = []\n",
    "            for filter_index in range (layer_idx):\n",
    "                loss, grad = gradient_ascent_step(img_tf, filter_index)\n",
    "                \n",
    "                if tf.reduce_sum(grad) <= 0.02 : #==0\n",
    "                    print(loss, grad.shape, ' Dead filter detected!',  filter_index) #layer.name,\n",
    "                    # print(tf.math.count_nonzero(grad))\n",
    "                    dead.append(filter_index)\n",
    "\n",
    "#             print('ReLU name: {}, ReLU index: {}'.format(layer_name, layer_idx +1))\n",
    "\n",
    "            while True:\n",
    "\n",
    "                conv = model.layers[layer_idx].name\n",
    "\n",
    "                if conv[-conv[::-1].find('_'):] == 'conv':\n",
    "\n",
    "                    conv_idx = find_layer_idx(model, conv)\n",
    "                    \n",
    "                    \n",
    "\n",
    "#                     print('Conv name: {}, Conv index: {}'.format(conv, conv_idx))\n",
    "\n",
    "#                     print('---')\n",
    "\n",
    "                    break\n",
    "\n",
    "                layer_idx -= 1\n",
    "            \n",
    "            \n",
    "            if dead != []:\n",
    "                if f'{conv}' in dead_filters.keys():\n",
    "                    dead_filters[f'{conv}'].append(dead)\n",
    "                else:\n",
    "                    dead_filters[f'{conv}'] = dead\n",
    "            \n",
    "# for layer in model.layers:\n",
    "\n",
    "#     layer_name = layer.name\n",
    "\n",
    "#     if layer_name[-layer_name[::-1].find('_'):] == 'relu':\n",
    "\n",
    "#         layer_idx =find_layer_idx(model, layer_name) -1\n",
    "\n",
    "#         print('ReLU name: {}, ReLU index: {}'.format(layer_name, layer_idx +1))\n",
    "\n",
    "#         while True:\n",
    "\n",
    "#             conv = model.layers[layer_idx].name\n",
    "\n",
    "#             if conv[-conv[::-1].find('_'):] == 'conv':\n",
    "\n",
    "#                 conv_idx = find_layer_idx(model, conv)\n",
    "\n",
    "#                 print('Conv name: {}, Conv index: {}'.format(conv, conv_idx))\n",
    "\n",
    "#                 print('---')\n",
    "\n",
    "#                 break\n",
    "\n",
    "#             layer_idx -= 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "44c5e2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dead_filters_resnet50v2_100image_.02grad.npy',dead_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51e3001a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dead_filters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7b8c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3fa02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dead_filters = {}\n",
    "\n",
    "# for img in images:\n",
    "#     img_tf = tf.convert_to_tensor(scale(img, 224, 224), np.float32)\n",
    "#     img_tf = tf.reshape(img_tf, [-1, 224, 224, 3])\n",
    "\n",
    "#     for layer in model.layers:\n",
    "#         print('Layer in Network:', layer.name)\n",
    "#         feature_extractor = keras.Model(inputs = model.inputs, outputs = layer.output)\n",
    "\n",
    "#         if layer.get_config().get('activation', None) == 'relu':\n",
    "#             print('Number of filters in layer:',layer.get_config().get('filters', None))\n",
    "#             num_filters = layer.get_config().get('filters', None)\n",
    "            \n",
    "#             dead = []\n",
    "#             for filter_index in range (num_filters):\n",
    "#                 loss, grad = gradient_ascent_step(img_tf, filter_index)\n",
    "                \n",
    "#                 if tf.reduce_sum(grad) <= 0.02 : #==0\n",
    "#                     print(loss, grad.shape, ' Dead filter detected!', layer.name, filter_index)\n",
    "#                     # print(tf.math.count_nonzero(grad))\n",
    "#                     dead.append(filter_index)\n",
    "#             if dead != []:\n",
    "#                 if f'{layer.name}' in dead_filters.keys():\n",
    "#                     dead_filters[f'{layer.name}'].append(dead)\n",
    "#                 else:\n",
    "#                     dead_filters[f'{layer.name}'] = dead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5f38000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_repeated(dictionary = {}, threshold = 0):\n",
    "    dic = {}\n",
    "    for key in dictionary.keys():\n",
    "        temp = []\n",
    "        for i in range(len(dictionary[key])):\n",
    "            if type(dictionary[key][i]) == int:\n",
    "                dictionary[key][i] = [dictionary[key][i]]\n",
    "            temp.extend(dictionary[key][i])\n",
    "        n, m = np.unique(temp, return_counts = True)\n",
    "        dic[key] = n, m\n",
    "    over_th = {}\n",
    "    for key in dic:\n",
    "        for i in range(len(dic[key][0])):\n",
    "            if dic[key][1][i] >= threshold:\n",
    "                if key in over_th.keys():\n",
    "                    over_th[key] = np.append(over_th[key], dic[key][0][i])\n",
    "                else:\n",
    "                    over_th.update({key: dic[key][0][i]})\n",
    "        if key in over_th.keys():\n",
    "            if type(over_th[key])== np.int32:\n",
    "                over_th[key] = np.array([over_th[key]])\n",
    "    return over_th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "afb8ac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dead_nerouns_new = most_repeated(dead_filters,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "692419a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dead_neroun_new_resnet50v2_100image_.02grad.npy',dead_nerouns_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4e3c09aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dead_nerouns_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92b97db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kerassurgeon\n",
    "from kerassurgeon.operations import delete_channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0456d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # dead_filters_name = [layer for layer in dead_nerouns_new]\n",
    "# # dead_filters_idx = [*dead_nerouns_new.values()]\n",
    "# # model.get_layer(model.get_layer(dead_filters_name[0]), dead_filters_idx[0]), dead_filters_idx[0]\n",
    "# print(model.get_layer(dead_filters_name[1]))\n",
    "# # new_model = delete_channels(model, model.get_layer(dead_filters_name[0]), dead_filters_idx[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a5d58c5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dead_filters_name = [layer for layer in dead_nerouns_new]\n",
    "dead_filters_idx = [*dead_nerouns_new.values()]\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[0]), dead_filters_idx[0])\n",
    "# for i in range(len(dead_filters_idx)-1):\n",
    "#     new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[i+1]), dead_filters_idx[i+1])\n",
    "# new_model.summary()\n",
    "\n",
    "\n",
    "# new_model = delete_channels(model,model.get_layer('conv1_conv'), [1, 2, 3, 4])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cc924bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = delete_channels(model, model.get_layer(dead_filters_name[0]), dead_filters_idx[0])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[1]), dead_filters_idx[1])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[2]), dead_filters_idx[2])\n",
    "# new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[3]), dead_filters_idx[0])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[4]), dead_filters_idx[4])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[5]), dead_filters_idx[5])\n",
    "# new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[6]), dead_filters_idx[0])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[7]), dead_filters_idx[7])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[8]), dead_filters_idx[8])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[9]), dead_filters_idx[0])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[10]), dead_filters_idx[10])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[11]), dead_filters_idx[11])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[12]), dead_filters_idx[0])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[13]), dead_filters_idx[13])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[14]), dead_filters_idx[14])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[15]), dead_filters_idx[0])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[16]), dead_filters_idx[16])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[17]), dead_filters_idx[17])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[18]), dead_filters_idx[0])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[19]), dead_filters_idx[19])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[20]), dead_filters_idx[20])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[21]), dead_filters_idx[0])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[22]), dead_filters_idx[22])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[23]), dead_filters_idx[23])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[24]), dead_filters_idx[24])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[25]), dead_filters_idx[25])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[25]), dead_filters_idx[26])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[27]), dead_filters_idx[27])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[28]), dead_filters_idx[28])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[29]), dead_filters_idx[29])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[30]), dead_filters_idx[30])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[31]), dead_filters_idx[31])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[32]), dead_filters_idx[32])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[33]), dead_filters_idx[33])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[34]), dead_filters_idx[34])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[35]), dead_filters_idx[35])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[36]), dead_filters_idx[36])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[37]), dead_filters_idx[37])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[38]), dead_filters_idx[38])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[39]), dead_filters_idx[39])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[40]), dead_filters_idx[40])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[41]), dead_filters_idx[41])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[42]), dead_filters_idx[42])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[43]), dead_filters_idx[43])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[44]), dead_filters_idx[44])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[45]), dead_filters_idx[45])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[46]), dead_filters_idx[46])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[47]), dead_filters_idx[47])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[48]), dead_filters_idx[48])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1ccec9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[9]), dead_filters_idx[0])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[10]), dead_filters_idx[10])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[11]), dead_filters_idx[11])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[12]), dead_filters_idx[0])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[13]), dead_filters_idx[13])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[14]), dead_filters_idx[14])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[15]), dead_filters_idx[0])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[16]), dead_filters_idx[16])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[17]), dead_filters_idx[17])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[18]), dead_filters_idx[0])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[19]), dead_filters_idx[19])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[20]), dead_filters_idx[20])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[21]), dead_filters_idx[0])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[22]), dead_filters_idx[22])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[23]), dead_filters_idx[23])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[24]), dead_filters_idx[24])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[25]), dead_filters_idx[25])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[26]), dead_filters_idx[26])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[27]), dead_filters_idx[27])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[28]), dead_filters_idx[28])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[29]), dead_filters_idx[29])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[30]), dead_filters_idx[30])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[31]), dead_filters_idx[31])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[32]), dead_filters_idx[32])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[33]), dead_filters_idx[33])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[34]), dead_filters_idx[34])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[35]), dead_filters_idx[35])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[36]), dead_filters_idx[36])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[37]), dead_filters_idx[37])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[38]), dead_filters_idx[38])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[39]), dead_filters_idx[39])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[40]), dead_filters_idx[40])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[41]), dead_filters_idx[41])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[42]), dead_filters_idx[42])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[43]), dead_filters_idx[43])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[44]), dead_filters_idx[44])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[45]), dead_filters_idx[45])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[46]), dead_filters_idx[46])\n",
    "new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[47]), dead_filters_idx[47])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[48]), dead_filters_idx[48])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ca07869",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6fa3c028",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.000001)\n",
    "    \n",
    "new_model.compile(\n",
    "  loss='categorical_crossentropy' ,\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2b1e2fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcs = ModelCheckpoint('/best_new_model.h5', monitor='val_accuracy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f86808f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z = new_model.fit(\n",
    "    training_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=30,\n",
    "     callbacks=[mcs,es]   )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2f86066",
   "metadata": {},
   "outputs": [],
   "source": [
    "dead_filters_new_model = {}\n",
    "\n",
    "for img in images:\n",
    "    img_tf = tf.convert_to_tensor(scale(img, 224, 224), np.float32)\n",
    "    img_tf = tf.reshape(img_tf, [-1, 224, 224, 3])\n",
    "\n",
    "    for layer in new_model.layers:\n",
    "\n",
    "        layer_name = layer.name\n",
    "        \n",
    "        feature_extractor = keras.Model(inputs = new_model.inputs, outputs = layer.output)\n",
    "\n",
    "        if layer_name[-layer_name[::-1].find('_'):] == 'relu':\n",
    "\n",
    "            layer_idx =find_layer_idx(new_model, layer_name) -1\n",
    "            \n",
    "            dead = []\n",
    "            for filter_index in range (layer_idx):\n",
    "                loss, grad = gradient_ascent_step(img_tf, filter_index)\n",
    "                \n",
    "                if tf.reduce_sum(grad) <= 0.02 : #==0\n",
    "                    print(loss, grad.shape, ' Dead filter detected!',  filter_index) #layer.name,\n",
    "                    # print(tf.math.count_nonzero(grad))\n",
    "                    dead.append(filter_index)\n",
    "\n",
    "#             print('ReLU name: {}, ReLU index: {}'.format(layer_name, layer_idx +1))\n",
    "\n",
    "            while True:\n",
    "\n",
    "                conv = new_model.layers[layer_idx].name\n",
    "\n",
    "                if conv[-conv[::-1].find('_'):] == 'conv':\n",
    "\n",
    "                    conv_idx = find_layer_idx(new_model, conv)\n",
    "                    \n",
    "                    \n",
    "\n",
    "#                     print('Conv name: {}, Conv index: {}'.format(conv, conv_idx))\n",
    "\n",
    "#                     print('---')\n",
    "\n",
    "                    break\n",
    "\n",
    "                layer_idx -= 1\n",
    "            \n",
    "            \n",
    "            if dead != []:\n",
    "                if f'{conv}' in dead_filters_new_model.keys():\n",
    "                    dead_filters_new_model[f'{conv}'].append(dead)\n",
    "                else:\n",
    "                    dead_filters_new_model[f'{conv}'] = dead\n",
    "            \n",
    "# for layer in model.layers:\n",
    "\n",
    "#     layer_name = layer.name\n",
    "\n",
    "#     if layer_name[-layer_name[::-1].find('_'):] == 'relu':\n",
    "\n",
    "#         layer_idx =find_layer_idx(model, layer_name) -1\n",
    "\n",
    "#         print('ReLU name: {}, ReLU index: {}'.format(layer_name, layer_idx +1))\n",
    "\n",
    "#         while True:\n",
    "\n",
    "#             conv = model.layers[layer_idx].name\n",
    "\n",
    "#             if conv[-conv[::-1].find('_'):] == 'conv':\n",
    "\n",
    "#                 conv_idx = find_layer_idx(model, conv)\n",
    "\n",
    "#                 print('Conv name: {}, Conv index: {}'.format(conv, conv_idx))\n",
    "\n",
    "#                 print('---')\n",
    "\n",
    "#                 break\n",
    "\n",
    "#             layer_idx -= 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "679366dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dead_filters_new_model_resnet50v2_100image_.02grad.npy',dead_filters_new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8bedf861",
   "metadata": {},
   "outputs": [],
   "source": [
    "dead_filters_new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eaf356b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dead_nerouns_new_model = most_repeated(dead_filters_new_model,80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68c8fbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dead_neroun_new_model_resnet50v2_100image_.02grad.npy',dead_nerouns_new_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0794fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dead_nerouns_new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "932cf692",
   "metadata": {},
   "outputs": [],
   "source": [
    "dead_filters_name = [layer for layer in dead_nerouns_new_model]\n",
    "dead_filters_idx = [*dead_nerouns_new_model.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e9cec19c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dead_filters_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "31bb511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model_1 = delete_channels(new_model, new_model.get_layer(dead_filters_name[0]), dead_filters_idx[0])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[1]), dead_filters_idx[1])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[2]), dead_filters_idx[2])\n",
    "# new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[3]), dead_filters_idx[0])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[4]), dead_filters_idx[4])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[5]), dead_filters_idx[5])\n",
    "# new_model = delete_channels(new_model, new_model.get_layer(dead_filters_name[6]), dead_filters_idx[0])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[7]), dead_filters_idx[7])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[8]), dead_filters_idx[8])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[9]), dead_filters_idx[0])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[10]), dead_filters_idx[10])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[11]), dead_filters_idx[11])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[12]), dead_filters_idx[0])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[13]), dead_filters_idx[13])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[14]), dead_filters_idx[14])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[15]), dead_filters_idx[0])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[16]), dead_filters_idx[16])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[17]), dead_filters_idx[17])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[18]), dead_filters_idx[0])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[19]), dead_filters_idx[19])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[20]), dead_filters_idx[20])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[21]), dead_filters_idx[0])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[22]), dead_filters_idx[22])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[23]), dead_filters_idx[23])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[24]), dead_filters_idx[24])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[25]), dead_filters_idx[25])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[26]), dead_filters_idx[26])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[27]), dead_filters_idx[27])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[28]), dead_filters_idx[28])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[29]), dead_filters_idx[29])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[30]), dead_filters_idx[30])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[31]), dead_filters_idx[31])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[32]), dead_filters_idx[32])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[33]), dead_filters_idx[33])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[34]), dead_filters_idx[34])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[35]), dead_filters_idx[35])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[36]), dead_filters_idx[36])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[37]), dead_filters_idx[37])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[38]), dead_filters_idx[38])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[39]), dead_filters_idx[39])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[40]), dead_filters_idx[40])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[41]), dead_filters_idx[41])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[42]), dead_filters_idx[42])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[43]), dead_filters_idx[43])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[44]), dead_filters_idx[44])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[45]), dead_filters_idx[45])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[46]), dead_filters_idx[46])\n",
    "new_model_1 = delete_channels(new_model_1, new_model_1.get_layer(dead_filters_name[47]), dead_filters_idx[47])\n",
    "# new_model = delete_channels(model, model.get_layer(dead_filters_name[48]), dead_filters_idx[48])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9472a975",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4fd4937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.000001)\n",
    "    \n",
    "new_model_1.compile(\n",
    "  loss='categorical_crossentropy' ,\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "39ac395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcss = ModelCheckpoint('/best_new_model_1.h5', monitor='val_accuracy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b700bec3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z = new_model_1.fit(\n",
    "    training_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=60,\n",
    "     callbacks=[mcss,es]   )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0d111674",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = new_model_1.fit(\n",
    "    training_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=40)\n",
    "     #callbacks=[mcss,es]   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ca4ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "\n",
    "    layer_name = layer.name\n",
    "\n",
    "    if layer_name[-layer_name[::-1].find('_'):] == 'relu':\n",
    "\n",
    "        layer_idx =find_layer_idx(model, layer_name) -1\n",
    "\n",
    "        print('ReLU name: {}, ReLU index: {}'.format(layer_name, layer_idx +1))\n",
    "\n",
    "        while True:\n",
    "\n",
    "            conv = model.layers[layer_idx].name\n",
    "\n",
    "            if conv[-conv[::-1].find('_'):] == 'conv':\n",
    "\n",
    "                conv_idx = find_layer_idx(model, conv)\n",
    "\n",
    "                print('Conv name: {}, Conv index: {}'.format(conv, conv_idx))\n",
    "\n",
    "                print('---')\n",
    "\n",
    "                break\n",
    "\n",
    "            layer_idx -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d4278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
